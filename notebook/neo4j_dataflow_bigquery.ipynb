{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/neo4j-partners/neo4j-google-cloud-dataflow/blob/main/notebook/neo4j_dataflow_bigquery.ipynb\" target=\"_blank\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/neo4j-partners/neo4j-google-cloud-dataflow/blob/main/notebook/neo4j_dataflow_bigquery.ipynb\" target=\"_blank\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/neo4j-partners/neo4j-google-cloud-dataflow/main/notebook/neo4j_dataflow_bigquery.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">Open in Vertex AI Workbench\n",
        "    </a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Overview\n",
        "This notebook will walk you through the steps of setting up everything you need to run through Neo4j Dataflow hands-on lab.\n",
        "Once you've set this up you will follow the rest of the tutorial and learn how to set up Google Cloud Dataflow to extract, transform, and load data from Google BigQuery into a Neo4j graph database instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up your development environment\n",
        "We suggest you use Colab for this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy your Neo4j Instance\n",
        "\n",
        "If you haven't done so already you will need to deploy an instance of Neo4j. This can be running anywhere in the world as long as it is accessible from the Internet. \n",
        "\n",
        "For this lab, however, we recommend deploying an instance of Aura from Google Cloud Platform. The links below will show you how to deploy an instance of AuraDS from Google Cloud Marketplace, however for this lab you can also deploy AuraDB Free. \n",
        "\n",
        "- Tutorial link: https://github.com/neo4j-partners/hands-on-lab-neo4j-and-vertex-ai/tree/main/Lab%201%20-%20Deploy%20Neo4j#lab-1---deploy-neo4j\n",
        "- Video link: https://youtu.be/27PMDtlSP4w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare your template files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install additional Packages\n",
        "First off, you'll also need to install a few packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --quiet google-cloud-storage\n",
        "!pip install --quiet python-dotenv\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    import IPython\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "except:\n",
        "    print('Please restart the kernel manually')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the sample job specification file \n",
        "We'll need to copy the sample job spec from the github repo to upload later to our Google Cloud Storage bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "job_spec_url = \"https://raw.githubusercontent.com/neo4j-partners/neo4j-google-cloud-dataflow/main/templates/bq-northwind-jobspec.json\"\n",
        "\n",
        "jobspec_filename = 'job_spec.json'\n",
        "connection_filename = 'neo4j_connection.json'\n",
        "\n",
        "# Download the sample job spec template from github\n",
        "download_cmd = \"wget -O \" + jobspec_filename + \" \" + job_spec_url\n",
        "print('download_cmd:', download_cmd)\n",
        "os.system(download_cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Neo4j connection file\n",
        "If you created an instance of Aura for this you can upload the credentials file below and it will automatically convert it to the correct JSON format. If you don't have this you will be taken through a dialogue to enter these manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "neo4j_creds = {}\n",
        "creds_uploaded=False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    from dotenv import dotenv_values\n",
        "    uploaded = files.upload()\n",
        "    print('uploaded:', uploaded)\n",
        "    try:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(\"Uploaded file:\", filename)\n",
        "        aura_creds = dotenv_values(filename)\n",
        "        for item in aura_creds:\n",
        "            print(item, '=', aura_creds[item])\n",
        "            neo4j_creds[item] = aura_creds[item]\n",
        "        creds_uploaded=True\n",
        "    except:\n",
        "        creds_uploaded=False\n",
        "\n",
        "if not creds_uploaded:\n",
        "    print('Enter the Aura connection values:')\n",
        "    neo4j_creds['NEO4J_URI'] = input('Neo4j URI: ')\n",
        "    neo4j_creds['NEO4J_USERNAME'] = input('Neo4j Username (\"neo4j\"): ') or 'neo4j'\n",
        "    neo4j_creds['NEO4J_PASSWORD'] = input('Neo4j Password: ') \n",
        "\n",
        "# Adding some default values needed for the Dataflow template\n",
        "neo4j_creds['NEO4J_DATABASE'] = 'neo4j'\n",
        "neo4j_creds['NEO4J_AUTHTYPE'] = 'basic'\n",
        "\n",
        "# Convert the values to the required key names and convert to JSON \n",
        "neo4j_auth = {}\n",
        "neo4j_auth['server_url'] = neo4j_creds['NEO4J_URI']\n",
        "neo4j_auth['database'] = neo4j_creds['NEO4J_DATABASE']\n",
        "neo4j_auth['auth_type'] = neo4j_creds['NEO4J_AUTHTYPE']\n",
        "neo4j_auth['username'] = neo4j_creds['NEO4J_USERNAME']\n",
        "neo4j_auth['pwd'] = neo4j_creds['NEO4J_PASSWORD']\n",
        "\n",
        "connection_json = json.dumps(neo4j_auth, indent=4)\n",
        "\n",
        "print('connection_json:')\n",
        "print(connection_json)\n",
        "print('')\n",
        "\n",
        "outfile = 'neo4j_connection.json'\n",
        "#print('Writing to file', outfile)\n",
        "print('Writing to file', connection_filename)\n",
        "\n",
        "f = open(outfile, \"w\")\n",
        "f.write(connection_json)\n",
        "f.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Google Cloud variables\n",
        "You'll need to set a few variables for your GCP environment.  PROJECT_ID and STORAGE_BUCKET are most critical.  The others will probably work with the defaults given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Edit these variables!\n",
        "PROJECT_ID = \"YOUR-PROJECT-ID\"\n",
        "STORAGE_BUCKET = \"YOUR-BUCKET-NAME\"\n",
        "\n",
        "# You can leave these defaults\n",
        "REGION = \"us-central1\"\n",
        "STORAGE_PATH = \"dataflow_templates\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authenticate your Google Cloud account\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload to a GCP Cloud Storage Bucket\n",
        "\n",
        "To get the data into Vertex AI, we must first put it in a bucket as a CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Create bucket (will add code later to check if it already exists or to create a unique name)\n",
        "client = storage.Client()\n",
        "bucket = client.bucket(STORAGE_BUCKET)\n",
        "client.create_bucket(bucket)\n",
        "\n",
        "template_files = []\n",
        "\n",
        "# Upload our files to that bucket\n",
        "for filename in [jobspec_filename, connection_filename]:\n",
        "    upload_path = os.path.join(STORAGE_PATH, filename)\n",
        "    blob = bucket.blob(upload_path)\n",
        "    blob.upload_from_filename(filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
